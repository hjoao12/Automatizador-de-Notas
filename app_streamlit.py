import streamlit as st
import os
import io
import time
import json
import zipfile
import uuid
import shutil
import unicodedata
import re
import hashlib
import pickle
import base64
import gc
import pandas as pd
from pathlib import Path
from pypdf import PdfReader, PdfWriter
import google.generativeai as genai
from pdf2image import convert_from_bytes
from PIL import Image
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed

# =====================================================================
# 1Ô∏è‚É£ CORRE√á√ÉO CR√çTICA: IMPORT DO PDF VIEWER
# =====================================================================
try:
    from streamlit_pdf_viewer import pdf_viewer
except ImportError:
    st.error("Biblioteca 'streamlit_pdf_viewer' n√£o encontrada. Instale com: pip install streamlit-pdf-viewer")
    pdf_viewer = None

# =====================================================================
# CONFIGURA√á√ÉO: TORNAR OCR OPCIONAL E SEGURO
# =====================================================================
try:
    import pytesseract
except ImportError:
    pytesseract = None  # Se n√£o estiver instalado, segue sem OCR

# =====================================================================
# CONFIGURA√á√ÉO INICIAL
# =====================================================================
st.set_page_config(
    page_title="Automatizador de Notas Fiscais",
    page_icon="üìÑ",
    layout="wide"
)
load_dotenv()

# =====================================================================
# DIRET√ìRIO TEMPOR√ÅRIO GLOBAL
# =====================================================================
TEMP_FOLDER = Path("./temp")
TEMP_FOLDER.mkdir(parents=True, exist_ok=True)

# Inicializa√ß√£o segura do Supabase
try:
    from supabase import create_client, Client
    
    @st.cache_resource
    def init_supabase():
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_KEY")
        if url and key:
            return create_client(url, key)
        return None
    
    supabase = init_supabase()
except ImportError:
    supabase = None
except Exception as e:
    print(f"Erro Supabase: {e}")
    supabase = None

# ======= CSS Corporativo Claro =======
st.markdown("""
<style>
body { background-color: #f8f9fa; color: #212529; font-family: 'Segoe UI', Roboto, Arial, sans-serif; }
[data-testid="stSidebar"] { background-color: #ffffff; border-right: 1px solid #e9ecef; }
h1, h2, h3, h4 { color: #0f4c81; }
div.stButton > button { background-color: #0f4c81; color: white; border-radius: 8px; border: none; font-weight: 500; }
div.stButton > button:hover { background-color: #0b3a5a; }
.stProgress > div > div > div > div { background-color: #28a745 !important; }
.success-log { color: #155724; background-color: #d4edda; padding: 6px 10px; border-radius: 6px; font-size: 0.9rem; margin-bottom: 2px; border-left: 4px solid #28a745; }
.warning-log { color: #856404; background-color: #fff3cd; padding: 6px 10px; border-radius: 6px; font-size: 0.9rem; margin-bottom: 2px; border-left: 4px solid #ffc107; }
.error-log { color: #721c24; background-color: #f8d7da; padding: 6px 10px; border-radius: 6px; font-size: 0.9rem; margin-bottom: 2px; border-left: 4px solid #dc3545; }
.info-log { color: #0c5460; background-color: #d1ecf1; padding: 6px 10px; border-radius: 6px; font-size: 0.9rem; margin-bottom: 2px; border-left: 4px solid #0c5460; }
.card { background: #fff; padding: 15px; border-radius:8px; box-shadow: 0 4px 12px rgba(15,76,129,0.08); margin-bottom:15px; }
.manage-panel { background: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 4px solid #0f4c81; margin: 10px 0; }
</style>
""", unsafe_allow_html=True)

st.title("Automatizador de Notas Fiscais PDF")

# =====================================================================
# SISTEMA DE CACHE INTELIGENTE
# =====================================================================
class DocumentCache:
    def __init__(self, cache_dir="./cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def get_cache_key(self, content_bytes, prompt):
        content_hash = hashlib.md5(content_bytes).hexdigest()
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()
        return f"{content_hash}_{prompt_hash}"
    
    def get(self, key):
        cache_file = self.cache_dir / f"{key}.pkl"
        if cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)
            except: return None
        return None
    
    def set(self, key, data):
        cache_file = self.cache_dir / f"{key}.pkl"
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(data, f)
        except: pass
    
    def clear(self):
        for cache_file in self.cache_dir.glob("*.pkl"):
            try: cache_file.unlink()
            except: pass

document_cache = DocumentCache()

# =====================================================================
# CONFIGURA√á√ÉO GEMINI
# =====================================================================
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GEMINI_API_KEY:
    try: GEMINI_API_KEY = st.secrets["GOOGLE_API_KEY"]
    except: pass

if not GEMINI_API_KEY:
    st.error("‚ùå Chave GOOGLE_API_KEY n√£o encontrada (.env ou secrets).")
    st.stop()

# Inicializa vari√°vel global
model = None

try:
    genai.configure(api_key=GEMINI_API_KEY)
    model_name_target = os.getenv("MODEL_NAME", "models/gemini-2.5-flash")
    model = genai.GenerativeModel(model_name_target)
except Exception as e:
    st.error(f"‚ùå Erro ao configurar Gemini ({model_name_target}): {str(e)}")

# =====================================================================
# FUN√á√ïES AUXILIARES
# =====================================================================
def get_patterns_db(): return st.session_state.get("db_patterns", {})
def sync_patterns_db(new_dict): return True
if "db_patterns" not in st.session_state: st.session_state["db_patterns"] = {}

def extrair_retry_after(erro_str):
    m = re.search(r"retry after (\d+)", erro_str.lower())
    if m: return int(m.group(1))
    m2 = re.search(r"seconds:\s*(\d+)", erro_str.lower())
    if m2 and "retry" in erro_str.lower(): return int(m2.group(1))
    m3 = re.search(r"retry in (\d+) minute", erro_str.lower())
    if m3: return int(m3.group(1)) * 60
    return None

def extrair_texto_ocr(img_bytes):
    if pytesseract is None: return ""
    try:
        img = Image.open(io.BytesIO(img_bytes))
        return pytesseract.image_to_string(img, lang="por")
    except: return ""

def _normalizar_texto(s: str) -> str:
    if not s: return ""
    s = unicodedata.normalize("NFKD", s).encode("ASCII", "ignore").decode("ASCII")
    s = re.sub(r"[^A-Z0-9 ]+", " ", s.upper())
    return re.sub(r"\s+", " ", s).strip()

def substituir_nome_emitente(nome_raw: str, cidade_raw: str = None) -> str:
    nome_norm = _normalizar_texto(nome_raw)
    cidade_norm = _normalizar_texto(cidade_raw) if cidade_raw else None
    if "SABARA" in nome_norm: return f"SB_{cidade_norm.split()[0]}" if cidade_norm else "SB"
    patterns = st.session_state.get("db_patterns", {})
    for padrao, substituto in patterns.items():
        if _normalizar_texto(padrao) in nome_norm: return substituto
    return re.sub(r"\s+", "_", nome_norm)

def limpar_emitente(nome: str) -> str:
    if not nome: return "SEM_NOME"
    nome = unicodedata.normalize("NFKD", nome).encode("ASCII", "ignore").decode("ASCII")
    nome = re.sub(r"[^A-Z0-9_]+", "_", nome.upper())
    return re.sub(r"_+", "_", nome).strip("_")

def limpar_numero(numero: str) -> str:
    if not numero: return "0"
    numero = re.sub(r"[^\d]", "", str(numero))
    return numero.lstrip("0") or "0"
    
def limpar_para_nome_arquivo(texto):
    if not texto: return "DESCONHECIDO"
    texto = re.sub(r'[\\/*?:"<>|]', "", texto)
    texto = unicodedata.normalize("NFKD", texto).encode("ASCII", "ignore").decode("ASCII")
    return texto.strip()[:60]

def validar_e_corrigir_dados(dados, texto_pdf_real=""):
    if not isinstance(dados, dict):
        if isinstance(dados, list) and len(dados) > 0 and isinstance(dados[0], dict): dados = dados[0]
        else: return {"emitente": "ERRO_FORMATO", "numero_nota": "000", "cidade": ""}
    
    dados_norm = {}
    for k, v in dados.items():
        k_lower = k.lower().strip()
        if any(x in k_lower for x in ["numero", "nota", "nfs", "danfe"]): key = "numero_nota"
        elif any(x in k_lower for x in ["emitente", "prestador", "social"]): key = "emitente"
        elif "cidade" in k_lower: key = "cidade"
        else: key = k
        dados_norm[key] = str(v) if v else ""
    dados = dados_norm

    raw_num = dados.get('numero_nota', '')
    numeros_limpos = re.sub(r'[^\d]', '', raw_num)

    if (not numeros_limpos or int(numeros_limpos) == 0) and texto_pdf_real:
        padroes_resgate = [r"N[¬∞¬∫o]\s*([0-9\.]+)", r"NF[ \-]*e?\s*[:.]?\s*([0-9\.]+)", r"N√∫mero\s*[:.]?\s*([0-9\.]+)"]
        for p in padroes_resgate:
            match = re.search(p, texto_pdf_real, re.IGNORECASE)
            if match:
                candidato = match.group(1).replace('.', '')
                if candidato.isdigit() and int(candidato) > 0:
                    dados['numero_nota'] = candidato
                    break
    
    final_num = re.sub(r'[^\d]', '', str(dados.get('numero_nota', '')))
    dados['numero_nota'] = final_num.lstrip('0') if final_num else "000"
    emitente = dados.get('emitente', '').strip()
    if not emitente: dados['emitente'] = "EMITENTE_DESCONHECIDO"
    else: dados['emitente'] = emitente
    if 'cidade' not in dados: dados['cidade'] = ""
    return dados

def extrair_pagina_inteira(pdf_bytes, page_idx, dpi=200):
    try:
        # ‚úÖ Corre√ß√£o: Agora acessamos a p√°gina espec√≠fica do PDF completo
        # first_page e last_page usam √≠ndice baseado em 1, por isso page_idx+1
        images = convert_from_bytes(pdf_bytes, dpi=dpi, first_page=page_idx+1, last_page=page_idx+1)
        if not images: return None
        
        img = images[0]
        if img.width > 2000:
            ratio = 2000 / float(img.width)
            img = img.resize((2000, int(float(img.height) * ratio)), Image.Resampling.LANCZOS)
        buf = io.BytesIO()
        img.save(buf, format="JPEG", quality=85, optimize=True)
        buf.seek(0)
        return buf.getvalue()
    except Exception as e:
        print(f"Erro na convers√£o de imagem: {e}")
        return None

# =====================================================================
# PROCESSAMENTO GEMINI
# =====================================================================
def processar_pagina_gemini(prompt, image_bytes):
    if model is None: return {"error": "Modelo Gemini n√£o configurado"}, False, 0, "None"
    start_time = time.time()
    max_retries = 10
    
    for tentativa in range(max_retries):
        try:
            image = Image.open(io.BytesIO(image_bytes))
            generation_config = genai.types.GenerationConfig(temperature=0.1, response_mime_type="application/json")
            response = model.generate_content([prompt, image], generation_config=generation_config)
            elapsed = time.time() - start_time
            
            if response.text:
                try:
                    text = response.text.replace("```json", "").replace("```", "")
                    text = re.sub(r",\s*}", "}", text)
                    text = re.sub(r",\s*]", "]", text)
                    dados = json.loads(text)
                    return dados, True, elapsed, "Gemini 2.5" 
                except json.JSONDecodeError: return {"error": "Falha ao decodificar JSON"}, False, elapsed, "Gemini 2.5"
            else: return {"error": "Resposta vazia da IA"}, False, elapsed, "Gemini 2.5"

        except Exception as e:
            erro_str = str(e)
            if "429" in erro_str or "Quota exceeded" in erro_str:
                sugerido = extrair_retry_after(erro_str)
                if sugerido:
                    wait_time = sugerido + 1
                    print(f"‚è≥ Cota cheia. Google pediu {sugerido}s. Aguardando {wait_time}s...")
                else:
                    wait_time = 5 * (2 ** tentativa)
                    print(f"‚ö†Ô∏è Cota cheia (sem tempo definido). Exponencial: {wait_time}s...")
                time.sleep(wait_time)
                continue 
            elapsed = time.time() - start_time
            return {"error": f"Erro API: {erro_str}"}, False, elapsed, "Gemini 2.5"
            
    return {"error": "Falha ap√≥s m√∫ltiplas tentativas (Cota)"}, False, time.time() - start_time, "Gemini 2.5"

def processar_pagina_worker(job_data, crop_ratio_override=None):
    pdf_bytes = job_data["bytes"] # ‚úÖ Agora recebe o PDF completo
    prompt = job_data["prompt"]
    name = job_data["name"]
    page_idx_original = job_data["page_idx"]
    
    # ‚úÖ CORRE√á√ÉO CR√çTICA 1: Usar o √≠ndice real da p√°gina
    page_idx_local = page_idx_original 
    
    gc.collect()

    try:
        # Valida√ß√£o simples (apenas para garantir que bytes s√£o v√°lidos)
        # reader = PdfReader(io.BytesIO(pdf_bytes)) # Opcional, custoso em loop, removido para performance

        # ‚úÖ CORRE√á√ÉO CR√çTICA 2: Cache Key inclui o n√∫mero da p√°gina
        cache_key = document_cache.get_cache_key(pdf_bytes, f"{prompt}_page_{page_idx_original}")
        
        cached_result = document_cache.get(cache_key)
        if cached_result and job_data.get("use_cache", True):
            # Retornamos o PDF completo nos bytes, mas precisamos saber que isso pode usar muita RAM se cachear o bin√°rio inteiro
            # O ideal seria n√£o retornar pdf_bytes no cache se ele for muito grande, mas mantendo a l√≥gica atual:
            return {**cached_result, "status": "CACHE", "name": name, "page_idx": page_idx_original, "pdf_bytes": None} 
            # Nota: Retornei pdf_bytes como None no cache hit para economizar RAM, o main loop deve lidar com isso se precisar re-fatiar.
            # AJUSTE: O main loop precisa do PDF de uma p√°gina s√≥ para salvar.
            # Vamos extrair a p√°gina √∫nica aqui para retornar ao loop principal.
            
            # Recriando o PDF de p√°gina √∫nica para o retorno (necess√°rio para o writer final)
            b = io.BytesIO(); w = PdfWriter(); r = PdfReader(io.BytesIO(pdf_bytes)); w.add_page(r.pages[page_idx_original]); w.write(b)
            single_page_bytes = b.getvalue()
            return {**cached_result, "status": "CACHE", "name": name, "page_idx": page_idx_original, "pdf_bytes": single_page_bytes}

        # Extra√ß√£o da imagem
        img_bytes = extrair_pagina_inteira(pdf_bytes, page_idx_local)
        if img_bytes is None: return {"status": "ERRO", "dados": {"emitente": "ERRO_IMG", "numero_nota": "000", "cidade": ""}, "tempo": 0, "provider": "System", "name": name, "page_idx": page_idx_original, "error_msg": "Falha IMG", "pdf_bytes": None, "texto_real": ""}

        texto_pdf_real = ""
        if pytesseract:
            texto_pdf_real = extrair_texto_ocr(img_bytes)
            if texto_pdf_real and len(texto_pdf_real) > 5000: texto_pdf_real = texto_pdf_real[:5000]

        print(f"[DEBUG] Chamando Gemini para {name}, p√°g {page_idx_original+1}")
        try:
            dados, ok, tempo, provider = processar_pagina_gemini(prompt, img_bytes)
        except Exception as e_gem:
            del img_bytes; gc.collect()
            return {"status": "ERRO", "dados": {"emitente": "", "numero_nota": "000", "cidade": ""}, "tempo": 0, "provider": "", "name": name, "page_idx": page_idx_original, "error_msg": f"Erro Gemini: {e_gem}", "pdf_bytes": None, "texto_real": texto_pdf_real}

        if not dados or not isinstance(dados, dict): dados = {"emitente": "", "numero_nota": "000", "cidade": ""}
        tem_dados = dados.get("emitente") != "EMITENTE_DESCONHECIDO" and dados.get("numero_nota") != "000"
        
        # ‚úÖ CORRE√á√ÉO 4: L√≥gica de Status
        if ok and tem_dados:
            status_final = "OK"
        elif ok:
            status_final = "REVISAR"
        else:
            status_final = "ERRO"

        # Criar PDF de p√°gina √∫nica para retorno (para salvar individualmente)
        b = io.BytesIO(); w = PdfWriter(); r = PdfReader(io.BytesIO(pdf_bytes)); w.add_page(r.pages[page_idx_original]); w.write(b)
        single_page_bytes = b.getvalue()

        resultado_final = {"status": status_final, "dados": dados, "tempo": tempo, "provider": provider, "name": name, "page_idx": page_idx_original, "pdf_bytes": single_page_bytes, "texto_real": texto_pdf_real}

        if status_final in ["OK", "REVISAR"] and "error" not in dados:
            document_cache.set(cache_key, {'dados': dados, 'tempo': tempo, 'provider': provider, 'texto_real': texto_pdf_real})
        
        del img_bytes; gc.collect()
        return resultado_final

    except Exception as e_outer:
        print(f"ERRO CRITICO WORKER: {e_outer}")
        return {"status": "ERRO", "dados": {"emitente": "", "numero_nota": "000", "cidade": ""}, "tempo": 0, "provider": "", "name": name, "page_idx": page_idx_original if 'page_idx_original' in locals() else 0, "error_msg": f"Erro cr√≠tico: {e_outer}", "pdf_bytes": None, "texto_real": texto_pdf_real if 'texto_pdf_real' in locals() else ""}

# =====================================================================
# UI & MAIN FLOW
# =====================================================================
with st.sidebar:
    st.markdown("### ‚öôÔ∏è Painel de Controle")
    if supabase: st.markdown("Status DB: <span style='color:green'><b>‚óè Conectado</b></span>", unsafe_allow_html=True)
    else: st.markdown("Status DB: <span style='color:orange'><b>‚óè Local (Offline)</b></span>", unsafe_allow_html=True)
    st.markdown("---")
    
    with st.expander("üõ†Ô∏è Prefer√™ncias", expanded=False):
        use_cache = st.toggle("Ativar Mem√≥ria R√°pida (Cache)", value=True)
        if st.button("üßπ Limpar Mem√≥ria", use_container_width=True):
            document_cache.clear(); st.toast("Mem√≥ria limpa!", icon="üßπ"); time.sleep(0.5); st.rerun()

    st.markdown("---")
    st.markdown("### üè∑Ô∏è Regras de Renomea√ß√£o")
    if "db_patterns" not in st.session_state: st.session_state["db_patterns"] = {}
    current_dict = st.session_state["db_patterns"]
    df_padroes = pd.DataFrame(list(current_dict.items()), columns=["origem", "destino"])
    df_editado = st.data_editor(df_padroes, num_rows="dynamic", use_container_width=True, hide_index=True, key="editor_patterns", column_config={"origem": st.column_config.TextColumn("üìÑ Texto no PDF", required=True, width="medium"), "destino": st.column_config.TextColumn("üè∑Ô∏è Novo Nome", required=True, width="small")})
    if st.button("üíæ Salvar Regras", type="primary", use_container_width=True):
        novo_dict = {str(r["origem"]).strip().upper(): str(r["destino"]).strip().upper() for i, r in df_editado.iterrows() if r["origem"]}
        st.session_state["db_patterns"] = novo_dict
        if sync_patterns_db(novo_dict): st.toast("Salvo na Nuvem!", icon="‚òÅÔ∏è")
        else: st.toast("Salvo Localmente!", icon="üíª")
        time.sleep(1); st.rerun()

def criar_dashboard_analitico():
    if "resultados" not in st.session_state: return
    st.markdown("---"); st.markdown("### üìä Dashboard Anal√≠tico")
    resultados = st.session_state["resultados"]
    logs = st.session_state.get("processed_logs", [])
    col1, col2, col3, col4 = st.columns(4)
    with col1: st.metric("üìÅ Arquivos Gerados", len(resultados))
    with col2: st.metric("üìÑ P√°ginas Processadas", sum(r.get('pages', 1) for r in resultados))
    with col3: st.metric("‚úÖ Sucessos", len([log for log in logs if log[2] == "OK"]))
    with col4: st.metric("‚ö†Ô∏è Revis√£o/Erros", len([log for log in logs if log[2] != "OK"]))

st.markdown('<div class="card">', unsafe_allow_html=True)
st.markdown("### üìé Enviar PDFs")
uploaded_files = st.file_uploader("Arraste e solte seus PDFs aqui", type=["pdf"], accept_multiple_files=True, key="uploader")
col_up_a, col_up_b = st.columns([1,1])
with col_up_a: process_btn = st.button("üöÄ Processar PDFs", type="primary", use_container_width=True)
with col_up_b: clear_session = st.button("‚ôªÔ∏è Limpar sess√£o", use_container_width=True)
st.markdown("</div>", unsafe_allow_html=True)

if clear_session:
    if "session_folder" in st.session_state:
        try: shutil.rmtree(st.session_state["session_folder"])
        except: pass
    keys_to_clear = ["resultados", "session_folder", "novos_nomes", "processed_logs", "files_meta", "selected_files", "_manage_target"]
    for k in keys_to_clear:
        if k in st.session_state: del st.session_state[k]
    st.rerun()

if uploaded_files and process_btn:
    session_id = str(uuid.uuid4())
    session_folder = TEMP_FOLDER / session_id
    os.makedirs(session_folder, exist_ok=True)

    arquivos = []
    # --- UX: MOSTRAR LOG ANTES DO PROCESSAMENTO PESADO ---
    with st.expander("üëÅÔ∏è Ver Logs de Processamento em Tempo Real", expanded=True):
        log_placeholder = st.empty()
    real_time_logs_html = [f"<div class='info-log'>üîÑ Iniciando... Preparando {len(uploaded_files)} arquivos...</div>"]
    log_placeholder.markdown("".join(real_time_logs_html), unsafe_allow_html=True)
    # -------------------------------------------------------

    with st.spinner("‚è≥ Processando documentos..."):
        for f in uploaded_files:
            try: arquivos.append({"name": f.name, "bytes": f.read()})
            except: st.warning(f"Erro ao ler {f.name}, ignorado.")

        jobs = []
        prompt = """Documento: NOTA FISCAL BRASILEIRA (NF-e / DANFE), PDF ESCANEADO (imagem).
Use SOMENTE vis√£o computacional (OCR visual).
N√ÉO utilize texto selecion√°vel do PDF.
Extraia: "emitente", "numero_nota", "cidade".
Retorne APENAS JSON v√°lido: { "emitente": "", "numero_nota": "", "cidade": "" }"""

        # ‚úÖ AJUSTE NO LOOP PRINCIPAL:
        # N√£o fatiamos mais o PDF aqui. Enviamos o PDF inteiro e o √≠ndice.
        # Isso economiza tempo de "PdfWriter" no loop e permite que o worker saiba o contexto real.
        for a in arquivos:
            try:
                reader = PdfReader(io.BytesIO(a["bytes"]))
                total_pages = len(reader.pages)
                for idx in range(total_pages):
                    jobs.append({
                        "bytes": a["bytes"], # Passa o blob original completo
                        "prompt": prompt, 
                        "name": a["name"], 
                        "page_idx": idx, 
                        "use_cache": st.session_state.get("use_cache", True)
                    })
            except Exception as e: st.error(f"Erro ao ler {a['name']}: {e}")

        agrupados_dados = {}
        processed_logs = []
        processed_count = 0
        progress_bar = st.progress(0.0)
        start_all = time.time()
        
        # ‚úÖ CORRE√á√ÉO 3: MAX_WORKERS = 1 para Free Tier
        MAX_WORKERS = 1 
        total_jobs = len(jobs) if jobs else 1
        
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_job = {executor.submit(processar_pagina_worker, job): job for job in jobs}
            
            for future in as_completed(future_to_job):
                processed_count += 1
                try:
                    result = future.result()
                    name = result["name"]; idx = result["page_idx"]; page_label = f"{name} (p√°g {idx+1})"
                    
                    status = result["status"]
                    
                    if status == "ERRO":
                        msg_erro = result.get("error_msg") or "Erro desconhecido"
                        log_info = f"FALHA: {msg_erro}"; css_class = "error-log"
                        dados_iniciais = {"emitente": "", "numero_nota": "000", "cidade": "" }
                    else:
                        dados_iniciais = result["dados"]
                        dados = validar_e_corrigir_dados(dados_iniciais, result.get("texto_real", ""))
                        
                        log_info = f"{dados.get('numero_nota')} | {dados.get('emitente')[:20]}"
                        
                        # ‚úÖ CSS baseado no novo status REVISAR/OK
                        if status == "REVISAR": css_class = "warning-log"
                        elif status == "OK": css_class = "success-log"
                        else: css_class = "info-log" # Cache ou outro

                        emitente_raw = dados.get("emitente", "") or f"REVISAR_{idx}"
                        numero_raw = dados.get("numero_nota", "") or "000"
                        cidade_raw = dados.get("cidade", "") or ""
                        numero = limpar_numero(numero_raw)
                        
                        if numero == "0" or numero == "000":
                            emitente = f"REVISAR_{limpar_emitente(emitente_raw)}"
                            key = (f"000_REV_{idx}_{uuid.uuid4().hex[:4]}", emitente, name)    
                        else:
                            nome_map = substituir_nome_emitente(emitente_raw, cidade_raw)
                            emitente = limpar_emitente(nome_map)
                            key = (numero, emitente, name)
                        
                        if result.get("pdf_bytes"): # S√≥ adiciona se tiver o PDF da p√°gina
                            agrupados_dados.setdefault(key, []).append({"page_idx": idx, "pdf_bytes": result["pdf_bytes"], "file_origin": name})

                    processed_logs.append((page_label, result["tempo"], status, log_info, result["provider"]))
                    
                    # --- ATUALIZA LOG EM TEMPO REAL ---
                    new_line = f"<div class='{css_class}'>üìù {page_label} [{status}]: {log_info}</div>"
                    real_time_logs_html.append(new_line)
                    log_placeholder.markdown("".join(real_time_logs_html[-20:]), unsafe_allow_html=True)

                except Exception as e: st.error(f"Erro cr√≠tico no loop: {e}")
                progress_bar.progress(min(processed_count/total_jobs, 1.0))

        resultados = []; files_meta = {}
        for (numero, emitente, _), pages_list in agrupados_dados.items():
            pages_list.sort(key=lambda x: (x['file_origin'], x['page_idx']))
            writer = PdfWriter()
            for p_data in pages_list:
                try:
                    r = PdfReader(io.BytesIO(p_data["pdf_bytes"]))
                    for p in r.pages: writer.add_page(p)
                except: continue
            emitente_safe = limpar_para_nome_arquivo(emitente)
            nome_pdf = f"DOC {numero}_{emitente_safe}.pdf"
            caminho = session_folder / nome_pdf
            with open(caminho, "wb") as f_out: writer.write(f_out)
            resultados.append({"file": nome_pdf, "numero": numero, "emitente": emitente, "pages": len(pages_list)})
            files_meta[nome_pdf] = {"numero": numero, "emitente": emitente, "pages": len(pages_list)}

        gc.collect() 
        st.session_state["resultados"] = resultados
        st.session_state["session_folder"] = str(session_folder)
        st.session_state["novos_nomes"] = {r["file"]: r["file"] for r in resultados}
        st.session_state["processed_logs"] = processed_logs
        st.session_state["files_meta"] = files_meta

    st.success(f"‚úÖ Processamento conclu√≠do em {round(time.time() - start_all, 2)}s.")
    criar_dashboard_analitico()
    time.sleep(1)
    st.rerun()

if "resultados" in st.session_state:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### üóÇÔ∏è Gerenciamento")
    resultados = st.session_state["resultados"]
    session_folder = Path(st.session_state["session_folder"])
    novos_nomes = st.session_state.get("novos_nomes", {r["file"]: r["file"] for r in resultados})
    files_meta = st.session_state.get("files_meta", {})

    col1, col2, col3, col4 = st.columns([3, 2, 2, 3])
    with col1: q = st.text_input("üîé Buscar", placeholder="Emitente ou n√∫mero...", label_visibility="collapsed")
    with col2: sort_by = st.selectbox("Ordenar", ["Nome (A-Z)", "Nome (Z-A)", "N√∫mero (asc)", "N√∫mero (desc)"], label_visibility="collapsed")
    with col3: show_logs = st.toggle("Ver Logs")
    with col4:
        c_act = st.columns(3)
        with c_act[0]:
            if st.button("‚¨áÔ∏è", help="Baixar Selecionados"):
                sel = st.session_state.get("selected_files", [])
                if sel:
                    mem = io.BytesIO(); 
                    with zipfile.ZipFile(mem, "w") as zf:
                        for f in sel:
                            src = session_folder / f
                            if src.exists(): zf.write(src, arcname=novos_nomes.get(f, f))
                    mem.seek(0)
                    st.download_button("üíæ", data=mem, file_name="selecionados.zip", mime="application/zip")
        with c_act[1]:
            if st.button("üóëÔ∏è", help="Excluir Selecionados"):
                sel = st.session_state.get("selected_files", [])
                if sel:
                    for f in sel:
                        try: (session_folder/f).unlink()
                        except: pass
                        st.session_state["resultados"] = [r for r in st.session_state["resultados"] if r["file"] != f]
                    st.session_state["selected_files"] = []; st.rerun()
        with c_act[2]:
            if st.button("üîó", help="Unir Selecionados"):
                sel = st.session_state.get("selected_files", [])
                if len(sel) > 1:
                    m = PdfWriter()
                    for f in sorted(sel):
                        try:
                            r = PdfReader(str(session_folder/f)); 
                            for p in r.pages: m.add_page(p)
                        except: pass
                    nm = f"AGRUPADO_{int(time.time())}.pdf"
                    with open(session_folder/nm, "wb") as f: m.write(f)
                    meta = {"file": nm, "numero": "AGRUP", "emitente": "V√ÅRIOS", "pages": len(m.pages)}
                    st.session_state["resultados"].insert(0, meta)
                    st.session_state["files_meta"][nm] = meta
                    st.session_state["novos_nomes"][nm] = nm
                    st.rerun()
    st.markdown("</div>", unsafe_allow_html=True)
    
    visible = resultados.copy()
    if q:
        q_up = q.strip().upper()
        visible = [r for r in visible if q_up in r["file"].upper() or q_up in r["emitente"].upper() or q_up in r["numero"]]
    if sort_by == "Nome (A-Z)": visible.sort(key=lambda x: x["file"])
    elif sort_by == "Nome (Z-A)": visible.sort(key=lambda x: x["file"], reverse=True)
    elif sort_by == "N√∫mero (asc)": visible.sort(key=lambda x: int(x["numero"]) if x["numero"].isdigit() else 0)
    else: visible.sort(key=lambda x: int(x["numero"]) if x["numero"].isdigit() else 0, reverse=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    if "selected_files" not in st.session_state: st.session_state["selected_files"] = []
    for r in visible:
        fn = r["file"]; ck = fn in st.session_state["selected_files"]
        c = st.columns([0.05, 0.5, 0.25, 0.2])
        if c[0].checkbox("", value=ck, key=f"cb_{fn}"):
            if fn not in st.session_state["selected_files"]: st.session_state["selected_files"].append(fn)
        else:
            if fn in st.session_state["selected_files"]: st.session_state["selected_files"].remove(fn)
        novos_nomes[fn] = c[1].text_input(fn, value=novos_nomes.get(fn, fn), key=f"ren_{fn}", label_visibility="collapsed")
        c[2].caption(f"üè¢ {r['emitente']}<br>üî¢ N¬∫ {r['numero']}", unsafe_allow_html=True)
        if c[3].button("‚öôÔ∏è Editar", key=f"m_{fn}"): st.session_state["_manage_target"] = fn; st.rerun()
    st.markdown("</div>", unsafe_allow_html=True)
    
    if "_manage_target" in st.session_state:
        tgt = st.session_state["_manage_target"]
        if not (session_folder/tgt).exists(): st.session_state.pop("_manage_target"); st.rerun()
        st.markdown('<div class="manage-panel">', unsafe_allow_html=True)
        c1, c2 = st.columns([0.9, 0.1]); c1.markdown(f"üõ†Ô∏è Editando: **{tgt}**")
        if c2.button("‚ùå", help="Fechar"): st.session_state.pop("_manage_target"); st.rerun()
        with st.expander("üëÅÔ∏è Visualizar PDF", expanded=True):
            if pdf_viewer: pdf_viewer(str(session_folder/tgt), height=600)
            else: st.warning("Visualizador de PDF n√£o dispon√≠vel. Instale streamlit-pdf-viewer.")
        try:
            reader_obj = PdfReader(str(session_folder/tgt)); total_pgs = len(reader_obj.pages)
            pgs = [f"P√°g {i+1}" for i in range(total_pgs)]
            sel_pgs = st.multiselect("Selecionar p√°ginas para a√ß√£o:", range(total_pgs), format_func=lambda x: pgs[x])
            meta_original = st.session_state["files_meta"].get(tgt, {"numero": "000", "emitente": "DESC"})
            c_a, c_b = st.columns(2)
            if c_a.button("‚úÇÔ∏è Separar Selecionadas (Criar novo PDF)"):
                if sel_pgs:
                    nw = PdfWriter()
                    for i in sorted(sel_pgs): nw.add_page(reader_obj.pages[i])
                    nn = f"{tgt[:-4]}_parte.pdf"
                    with open(session_folder/nn, "wb") as f: nw.write(f)
                    nm = {"file": nn, "numero": meta_original["numero"], "emitente": meta_original["emitente"], "pages": len(sel_pgs)}
                    st.session_state["resultados"].append(nm); st.session_state["files_meta"][nn] = nm; st.session_state["novos_nomes"][nn] = nm
                    st.success(f"Criado: {nn}")
            if c_b.button("üóëÔ∏è Remover Selecionadas (Do PDF atual)"):
                if sel_pgs:
                    nw = PdfWriter(); keep_count = 0
                    for i in range(total_pgs):
                        if i not in sel_pgs: nw.add_page(reader_obj.pages[i]); keep_count += 1
                    if keep_count > 0:
                        with open(session_folder/tgt, "wb") as f: nw.write(f)
                        st.session_state["files_meta"][tgt]["pages"] = keep_count
                        for x in st.session_state["resultados"]:
                            if x["file"] == tgt: x["pages"] = keep_count
                        st.rerun()
                    else:
                        (session_folder/tgt).unlink()
                        st.session_state["resultados"] = [x for x in st.session_state["resultados"] if x["file"] != tgt]
                        st.session_state.pop("_manage_target"); st.rerun()
        except Exception as e: st.error(f"Erro ao manipular PDF: {e}")
        st.markdown("</div>", unsafe_allow_html=True)

    if show_logs:
        st.caption("Logs recentes:")
        for log in st.session_state.get("processed_logs", [])[-10:]: st.text(f"{log[2]} | {log[3]} ({log[1]}s)")
    st.markdown("---")
    if st.button("‚¨áÔ∏è BAIXAR TUDO (.ZIP)", type="primary", use_container_width=True):
        mem = io.BytesIO()
        with zipfile.ZipFile(mem, "w") as zf:
            for r in resultados:
                src = session_folder / r["file"]
                if src.exists(): zf.write(src, arcname=novos_nomes.get(r["file"], r["file"]))
        mem.seek(0)
        st.download_button("Clique para salvar o ZIP final", data=mem, file_name="notas_fiscais_processadas.zip", mime="application/zip")